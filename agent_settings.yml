# Force the agent to use the proxy URL instead of reaching out to the internet
openai-api-base: http://proxy:4000

# Set default model (matches a 'model_name' from proxy_config.yaml)
model: openai/gemini-flash

# Silence the Git prompt (Base name + false)
git: false

# Silence the interactive warnings and update notes
show-model-warnings: false
show-release-notes: false
# Prevent Aider from trying to auto-update itself inside the container
check-update: false

# Auto-accept all file creation, deletion, and context prompts
yes-always: true

# Add prompts.md as a persistent read-only file in the chat context
read: /tmp/prompts.md

